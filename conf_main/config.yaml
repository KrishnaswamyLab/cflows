data:
  phate_path: "${hydra:runtime.cwd}/../data_main/X_phate.npy"
  pca_path: "${hydra:runtime.cwd}/../data_main/X_pca.npy"
  phate_vis_path: "${hydra:runtime.cwd}/../data_main/X_phate_vis.npy"
  weights_path: "${hydra:runtime.cwd}/../data_main/var_ratio.npy"
  train_ratio: 0.7
  val_ratio: 0.15  # test_ratio will be 1 - train_ratio - val_ratio = 0.15

save:
  enabled: true  # master switch for saving
  model_dir: "${hydra:runtime.cwd}/../saved_model"  # single directory for all files

model:
  layer_widths: [32, 32]
  dropout: 0.1
  batchnorm: true
  weight_decay: 0.0001
  lr: 0.001
  scheduler:
    name: "reduce_on_plateau"  # options: reduce_on_plateau, cosine, step
    patience: 5  # for reduce_on_plateau and step
    factor: 0.5  # reduction factor
    min_lr: 1e-6
    monitor: "val_loss"  # for reduce_on_plateau
    # Additional params for cosine
    # T_max: will use max_epochs
    # eta_min: will use min_lr

training:
  batch_size: 32
  drop_last: true
  max_epochs: 25
  accelerator: "gpu"
  devices: 1
  num_workers: 4
  early_stopping_patience: 10
  early_stopping_min_delta: 1e-4

logging:
  logger: "wandb"  # options: "wandb", "tensorboard", "none"
  wandb_project: "mioflow_decoder"
  tensorboard_dir: "tensorboard_logs"
  checkpoint_dir: "checkpoints"
  save_top_k: 1
  monitor_metric: "val_loss"  # used for both checkpointing and early stopping
  monitor_mode: "min"
  log_every_n_steps: 1
  # run_name: null  # Optional: Specify a custom run name
  # run_name: null  # Optional: Specify a custom run name for wandb 